{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "335c924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import json \n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d69c00c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90a2c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"data/music_related/\"\n",
    "ignore_files = [\"all_music_tweets.ndjson\", \".ipynb_checkpoints\"] # ignore these files in the iteration \n",
    "\n",
    "for file in os.listdir(dir): #read all the files in the directory\n",
    "    if file not in ignore_files: #ignore the two files from above\n",
    "        with open(dir + file) as f: #open each file\n",
    "            lines = f.readlines() #read all the lines in the file\n",
    "            \n",
    "            for line in lines: #looping through the tweets in each file\n",
    "                tweet = json.loads(line.strip()) #tweet now contains the atributes of the line (tweet) we're looping through \n",
    "                \n",
    "                if not tweet[\"text\"].startswith(\"RT @\"): #excluding RT's\n",
    "                    tweet_data = {} #saving the coloumns we want from non-RT tweets\n",
    "                    tweet_data[\"id\"] = tweet[\"id\"] #tweet ID\n",
    "                    tweet_data[\"user_id\"] = tweet[\"from_user_id\"] #user ID\n",
    "                         \n",
    "                    date = datetime.strptime(tweet[\"created_at\"], \"%a %b %d %H:%M:%S %z %Y\") #re-formatting date\n",
    "                    tweet_data[\"date\"] = date.date() #date\n",
    "                    \n",
    "                    url = re.findall(\"https:\\/\\/t.co\\/[a-zA-Z0-9]{10}\", tweet[\"text\"])\n",
    "                    if len(url) > 0:\n",
    "                        tweet_data[\"link\"] = url #link from tweets\n",
    "                    else : \n",
    "                        tweet_data[\"link\"] = \"\"\n",
    "\n",
    "                    tweet_data[\"texts\"] = re.sub(\"https:\\/\\/t.co\\/[a-zA-Z0-9]{10}\", \"\", tweet[\"text\"]) #text + removing the link\n",
    "                    \n",
    "                    tweet_data[\"country\"] = tweet[\"user_location\"][\"country_code\"] #country\n",
    "                    if \"state\" in tweet[\"user_location\"].keys(): #some tweets don't have states, but if they do we want it\n",
    "                        tweet_data[\"state\"] = tweet[\"user_location\"][\"state\"] #state\n",
    "                    else: \n",
    "                        tweet_data[\"state\"] = \"\" #otherwise they are empty \n",
    "               \n",
    "                    data.append(tweet_data) #putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aebcbbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data) #making it a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7be02d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"test.csv\", index=False) #saving as a csv-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a46d02",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
